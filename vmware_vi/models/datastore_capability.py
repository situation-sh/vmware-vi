# coding: utf-8

"""
    Virtual Infrastructure JSON API

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 8.0.1.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json


from typing import Any, ClassVar, Dict, List, Optional
from pydantic import StrictBool
from pydantic import Field
from vmware_vi.models.data_object import DataObject
try:
    from typing import Self
except ImportError:
    from typing_extensions import Self

class DatastoreCapability(DataObject):
    """
    Information about the capabilities of this datastore. 
    """ # noqa: E501
    directory_hierarchy_supported: StrictBool = Field(description="Indicates whether or not directories can be created on this datastore. ", alias="directoryHierarchySupported")
    raw_disk_mappings_supported: StrictBool = Field(description="Indicates whether or not raw disk mappings can be created on this datastore. ", alias="rawDiskMappingsSupported")
    per_file_thin_provisioning_supported: StrictBool = Field(description="Indicates whether or not the datastore supports thin provisioning on a per file basis.  When thin provisioning is used, backing storage is lazily allocated.  This is supported by VMFS3. VMFS2 always allocates storage eagerly. Thus, this value is false for VMFS2. Most NAS systems always use thin provisioning. They do not support configuring this on a per file basis, so for NAS systems this value is also false. ", alias="perFileThinProvisioningSupported")
    storage_iorm_supported: StrictBool = Field(description="Indicates whether the datastore supports Storage I/O Resource Management.  ***Since:*** vSphere API 4.1 ", alias="storageIORMSupported")
    native_snapshot_supported: StrictBool = Field(description="Indicates whether the datastore supports native snapshot feature which is based on Copy-On-Write.  ***Since:*** vSphere API 5.1 ", alias="nativeSnapshotSupported")
    top_level_directory_create_supported: Optional[StrictBool] = Field(default=None, description="Indicates whether the datastore supports traditional top-level directory creation.  See also *DatastoreNamespaceManager*.  ***Since:*** vSphere API 5.5 ", alias="topLevelDirectoryCreateSupported")
    se_sparse_supported: Optional[StrictBool] = Field(default=None, description="Indicates whether the datastore supports the Flex-SE(SeSparse) feature.  ***Since:*** vSphere API 5.5 ", alias="seSparseSupported")
    vmfs_sparse_supported: Optional[StrictBool] = Field(default=None, description="Indicates whether the datastore supports the vmfsSparse feature.  True for VMFS3/VMFS5/NFS/NFS41, False for VMFS6. If value is undefined, then it should be read as supported.  ***Since:*** vSphere API 6.5 ", alias="vmfsSparseSupported")
    vsan_sparse_supported: Optional[StrictBool] = Field(default=None, description="Indicates whether the datastore supports the vsanSparse feature.  ***Since:*** vSphere API 6.5 ", alias="vsanSparseSupported")
    upit_supported: Optional[StrictBool] = Field(default=None, description="Deprecated as of vSphere API 8.0, and there is no replacement for it.  Indicates whether the datastore supports the upit feature.  ***Since:*** vSphere API 6.5 ", alias="upitSupported")
    vmdk_expand_supported: Optional[StrictBool] = Field(default=None, description="On certain datastores (e.g.  2016 PMEM datastore) VMDK expand is not supported. This field tells user if VMDK on this datastore can be expanded or not. If value is undefined, then it should be read as supported.  ***Since:*** vSphere API 6.7 ", alias="vmdkExpandSupported")
    clustered_vmdk_supported: Optional[StrictBool] = Field(default=None, description="Indicates whether the datastore supports clustered VMDK feature.  ***Since:*** vSphere API 7.0 ", alias="clusteredVmdkSupported")
    __properties: ClassVar[List[str]] = ["_typeName"]

    model_config = {
        "populate_by_name": True,
        "validate_assignment": True
    }


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Create an instance of DatastoreCapability from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        _dict = self.model_dump(
            by_alias=True,
            exclude={
            },
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Dict) -> Self:
        """Create an instance of DatastoreCapability from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "_typeName": obj.get("_typeName")
        })
        return _obj


