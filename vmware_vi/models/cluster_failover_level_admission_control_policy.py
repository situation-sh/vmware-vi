# coding: utf-8

"""
    Virtual Infrastructure JSON API

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 8.0.1.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json


from typing import Any, ClassVar, Dict, List, Optional
from pydantic import StrictInt
from pydantic import Field
from vmware_vi.models.cluster_das_admission_control_policy import ClusterDasAdmissionControlPolicy
from vmware_vi.models.cluster_slot_policy import ClusterSlotPolicy
try:
    from typing import Self
except ImportError:
    from typing_extensions import Self

class ClusterFailoverLevelAdmissionControlPolicy(ClusterDasAdmissionControlPolicy):
    """
    The *ClusterFailoverLevelAdmissionControlPolicy* defines the number of host failures that should be tolerated and still guarantee enough unfragmented resources to failover all powered on virtual machines on those failed hosts.  When you use the failover level policy, vSphere HA partitions resources into slots. A slot represents the minimum CPU and memory resources that are required to support any powered-on virtual machine in the cluster.  With the failover level policy in place, HA uses the following slot calculations to control virtual machine migration within the cluster: 1. Calculate the slot size from CPU and memory reservations.    The CPU value is the largest CPU reservation for all powered-on    virtual machines in the cluster. The memory value is the largest    memory reservation (plus memory overhead).        If your cluster contains any virtual machines that have much larger    reservations than the others, they will distort slot size calculation.    To avoid this, you can specify an upper bound for slot sizes;    use the configuration editor in the vSphere Client to set the    das.slotCpuInMHz and das.slotMemInMB attributes. When you use these    attributes, there is a risk that resource fragmentation will cause    virtual machines with resource requirements larger than the slot size    to be assigned multiple slots. In a cluster that is close to capacity,    there might be enough slots in aggregate for HA to successfully    failover a virtual machine. However, if those slots are located    on multiple hosts, a virtual machine assigned multiple slots cannot    use them because a virtual machine can run on only a single host    at a time. 2. Determine how many slots each host in the cluster can hold.    HA uses the CPU and memory resources in a host's root resource pool    to determine host slot capacity, not the total physical resources    of the host. Resources used for virtualization purposes are not    included. HA uses connected hosts that are not in maintenance mode    and that do not have any HA errors.        The CPU slot resource is the host CPU resource amount divided    by the CPU component of the slot size; the result is rounded down.    HA makes the same calculation for host memory resource amount.    HA compares the results; the lower of the two numbers is the    host slot capacity. 3. Determine the current failover capacity of the cluster. This is the    number of hosts (starting from the largest) that can fail and still    leave enough slots to satisfy all of the powered-on virtual machines. 4. Compare the current failover capacity to the configured    *ClusterFailoverLevelAdmissionControlPolicy.failoverLevel*.    If the current failover capacity is less than the configured    failover level, HA disallows the operation.     ***Since:*** vSphere API 4.0 
    """ # noqa: E501
    failover_level: StrictInt = Field(description="Number of host failures that should be tolerated, still guaranteeing sufficient resources to restart virtual machines on available hosts.  ***Since:*** vSphere API 4.0 ", alias="failoverLevel")
    slot_policy: Optional[ClusterSlotPolicy] = Field(default=None, alias="slotPolicy")
    __properties: ClassVar[List[str]] = ["_typeName"]

    model_config = {
        "populate_by_name": True,
        "validate_assignment": True
    }


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Create an instance of ClusterFailoverLevelAdmissionControlPolicy from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        _dict = self.model_dump(
            by_alias=True,
            exclude={
            },
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Dict) -> Self:
        """Create an instance of ClusterFailoverLevelAdmissionControlPolicy from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "_typeName": obj.get("_typeName")
        })
        return _obj


